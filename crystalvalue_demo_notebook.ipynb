{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "A9YRrFYNY37s",
      "metadata": {
        "id": "A9YRrFYNY37s"
      },
      "source": [
        "# DISCLAIMER\n",
        "Copyright 2021 Google LLC. \n",
        "\n",
        "*This solution, including any related sample code or data, is made available on an “as is,” “as available,” and “with all faults” basis, solely for illustrative purposes, and without warranty or representation of any kind. This solution is experimental, unsupported and provided solely for your convenience. Your use of it is subject to your agreements with Google, as applicable, and may constitute a beta feature as defined under those agreements. To the extent that you make any data available to Google in connection with your use of the solution, you represent and warrant that you have all necessary and appropriate rights, consents and permissions to permit Google to use and process that data. By using any portion of this solution, you acknowledge, assume and accept all risks, known and unknown, associated with its usage, including with respect to your deployment of any portion of this solution in your systems, or usage in connection with your business, if at all.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iTsKaxLPY37t",
      "metadata": {
        "id": "iTsKaxLPY37t"
      },
      "source": [
        "# Estimating lifetime value of users via Crystalvalue\n",
        "\n",
        "**Crystalvalue** is a best practice comprehensive framework for running end-to-end LTV solutions leveraging Google Cloud Vertex AI AutoML.\n",
        "\n",
        "To illustrate how to use this library, this notebook uses the Online Retail II data set from Kaggle which contains all the transactions occurring for a UK-based and registered, non-store online retail between 01/12/2009 and 09/12/2011. The company mainly sells unique all-occasion gift-ware. More details on this dataset can be found here https://www.kaggle.com/mashlyn/online-retail-ii-uci."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WJajLx_EtUKR",
      "metadata": {
        "id": "WJajLx_EtUKR"
      },
      "source": [
        "# Set up - Getting access to the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iojPU3e4tW5z",
      "metadata": {
        "id": "iojPU3e4tW5z"
      },
      "source": [
        "In order to use the Kaggle’s public API, you must first authenticate using an API token. You can do this by visiting your Kaggle account and click 'Create New API Token' (See https://www.kaggle.com/docs/api). This will download an API token (called kaggle.json). Put this file in your working directory and run the following commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duYMfWZelG0f",
      "metadata": {
        "id": "duYMfWZelG0f"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6EXbt-qetckB",
      "metadata": {
        "id": "6EXbt-qetckB"
      },
      "source": [
        "Kaggle requires the json to be in a specific folder called 'kaggle'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d-0X-BPrtcIJ",
      "metadata": {
        "id": "d-0X-BPrtcIJ"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZyIa1VNTta-n",
      "metadata": {
        "id": "ZyIa1VNTta-n"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qessvI1tthFT",
      "metadata": {
        "id": "qessvI1tthFT"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d mashlyn/online-retail-ii-uci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cZPXzkP0tfoi",
      "metadata": {
        "id": "cZPXzkP0tfoi"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FQoIQXJBtjcZ",
      "metadata": {
        "id": "FQoIQXJBtjcZ"
      },
      "outputs": [],
      "source": [
        "!unzip online-retail-ii-uci.zip -d data/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sDA4zRGytlAx",
      "metadata": {
        "id": "sDA4zRGytlAx"
      },
      "source": [
        "This creates a CSV file which we will import into BigQuery in the next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1O4OhKV5Y37u",
      "metadata": {
        "id": "1O4OhKV5Y37u"
      },
      "source": [
        "# Installing dependencies and initializing Crystalvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shY9DhgMQ2AZ",
      "metadata": {
        "id": "shY9DhgMQ2AZ"
      },
      "source": [
        "Note: this notebook assumes you are working from the crystalvalue folder's parent directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m6gkj-aXY37u",
      "metadata": {
        "id": "m6gkj-aXY37u"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade -q -r './crystalvalue/requirements.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mKWzgxQ1Y37v",
      "metadata": {
        "id": "mKWzgxQ1Y37v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from crystalvalue import crystalvalue\n",
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TnNNkQNvY37v",
      "metadata": {
        "id": "TnNNkQNvY37v"
      },
      "outputs": [],
      "source": [
        "# Create BigQuery client for cloud authentication.\n",
        "bigquery_client = bigquery.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ySWcHL7DcKrd",
      "metadata": {
        "id": "ySWcHL7DcKrd"
      },
      "outputs": [],
      "source": [
        "# Read the data and rename the columns to be BiqQuery friendly.\n",
        "data = pd.read_csv('./data/online_retail_II.csv')\n",
        "data.columns = data.columns.str.replace(' ', '')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0qlNEnCjcL9f",
      "metadata": {
        "id": "0qlNEnCjcL9f"
      },
      "outputs": [],
      "source": [
        "# Load the data to Bigquery.\n",
        "dataset_id = 'your_dataset'  # Make sure this dataset exists in your project.\n",
        "table_name = 'online_retail_data'  # This is what we will call the table that will be created.\n",
        "location = 'europe-west1'  # This is the location of your dataset in Bigquery. Here we use 'europe-west1`.\n",
        "\n",
        "bigquery_job = bigquery_client.load_table_from_dataframe(\n",
        "      dataframe=data,\n",
        "      destination=f'{bigquery_client.project}.{dataset_id}.{table_name}',\n",
        "      location=location).result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gCVphBgXY37w",
      "metadata": {
        "id": "gCVphBgXY37w"
      },
      "outputs": [],
      "source": [
        "# Initiate the CrystalValue class with the relevant parameters.\n",
        "pipeline = crystalvalue.CrystalValue(\n",
        "  bigquery_client=bigquery_client,\n",
        "  dataset_id=dataset_id,  # Dataset ID containing the table.\n",
        "  customer_id_column='CustomerID',\n",
        "  date_column='InvoiceDate',\n",
        "  value_column='Price',  # column to use for LTV calculation.\n",
        "  days_lookback=90,  # How many days in the past to use for feature engineering.\n",
        "  days_lookahead=365,  # How many days in the future to use for value prediction.\n",
        "  location=location)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FHC77gHNcRDP",
      "metadata": {
        "id": "FHC77gHNcRDP"
      },
      "source": [
        "# Data Checks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xIfjG7zNcVtx",
      "metadata": {
        "id": "xIfjG7zNcVtx"
      },
      "source": [
        "CrystalValue will run some checks on your data to check if the data is suitable for LTV modelling and raise errors if not. This will also output a new BigQuery table in your dataset called `summary_statistics` with key information such as the number of customers, transactions and analysis time period. This information can be used to check for outliers or anomalies (e.g. negative prices). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CTiZxBvrcSeV",
      "metadata": {
        "id": "CTiZxBvrcSeV"
      },
      "outputs": [],
      "source": [
        "summary_statistics = pipeline.run_data_checks(\n",
        "    transaction_table_name=table_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Bcu6lMlY37w",
      "metadata": {
        "id": "5Bcu6lMlY37w"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "Crystalvalue takes a transaction level dataset and creates a machine learning-ready dataset that can be ingested by AutoML. Data types are automatically inferred from the BigQuery schema unless the features are provided using the feature_types parameter in the `.feature_engineer()` method. Data transformations are applied automatically depending on the data type. The data crunching happens in BigQuery and the executed script can be optionally written to your directory in case you want to look through it. The features will be created in a table called `training_data` by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yK5Lfb1SY37w",
      "metadata": {
        "id": "yK5Lfb1SY37w"
      },
      "outputs": [],
      "source": [
        "training_data = pipeline.feature_engineer(\n",
        "  transaction_table_name=table_name,\n",
        "  write_executed_query_file='crystalvalue/executed_query.sql'  # (Optional) File path to write the executed SQL query.\n",
        ")  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xQ0yaFbBY37x",
      "metadata": {
        "id": "xQ0yaFbBY37x"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3JCdyprSY37x",
      "metadata": {
        "id": "3JCdyprSY37x"
      },
      "source": [
        "Crystalvalue leverages AutoML Tabular models (Vertex AI) which requires an\n",
        "AutoML Dataset as an input. CrystalValue does this automatically as part of the 'training' step of the\n",
        "pipeline. This step typically takes about 2 or more hours to run. By default CrystalValue chooses the following parameters (configurable):\n",
        "*  Predefined split with random 15% of users as test, 15% in validation and 70% in\n",
        "training.\n",
        "*  Optimization objective as Minimize root-mean-squared error (RMSE). This is recommended but can be modified to [MAE or RMSLE](https://cloud.google.com/automl-tables/docs/train#opt-obj).\n",
        "*  1 node hour of training (1000 milli node hours). It is recommended to start with this training time. [Modify this in line with the number of rows](https://cloud.google.com/automl-tables/docs/train#training_a_model) in the dataset when you are ready for productionising. See information here about [pricing](https://cloud.google.com/automl-tables/pricing).\n",
        "\n",
        "In this example we keep all the default settings so training the model is as simple\n",
        "as calling pipeline.train(). For more details see:  \n",
        "https://cloud.google.com/vertex-ai/docs/datasets/create-dataset-api  \n",
        "https://cloud.google.com/vertex-ai/docs/training/automl-api  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PvryAnPFiuWG",
      "metadata": {
        "id": "PvryAnPFiuWG"
      },
      "source": [
        "Once you start the training, you can view your model training progress here:  \n",
        "https://console.cloud.google.com/vertex-ai/training/training-pipelines  \n",
        "Once the training is finished, check out your trained AutoML model in the UI. Feature importance graphs and statistics on the data can be viewed here:  \n",
        " https://console.cloud.google.com//vertex-ai/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CSK1FtHVY37y",
      "metadata": {
        "id": "CSK1FtHVY37y"
      },
      "outputs": [],
      "source": [
        "# Creates AI Platform Dataset and trains AutoML model.\n",
        "pipeline.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Dok2Wu6UY370",
      "metadata": {
        "id": "Dok2Wu6UY370"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wsJdx-MvY370",
      "metadata": {
        "id": "wsJdx-MvY370"
      },
      "source": [
        "To evaluate model goodness of fit, we use 3 criteria:\n",
        "\n",
        "* Bin level Charts - predicted vs actual LTV by decile\n",
        "* Spearman Correlation \n",
        "* Normalized Gini coefficient\n",
        "\n",
        "The following commands deploys your model (which is required for evaluation) and then it performs the model evaluation. To ensure consistency and comparision across model runs, these outputs are sent to a BigQuery table (by default called `crystalvalue_evaluation`) that can capture changes in model performance over all iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dxA48EdTcs3c",
      "metadata": {
        "id": "dxA48EdTcs3c"
      },
      "outputs": [],
      "source": [
        "pipeline.deploy_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TmTV4LayjXo9",
      "metadata": {
        "id": "TmTV4LayjXo9"
      },
      "outputs": [],
      "source": [
        "pipeline.evaluate_model(endpoint='23554634534545')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oJ6ZFLwrY37y",
      "metadata": {
        "id": "oJ6ZFLwrY37y"
      },
      "source": [
        "# Generating predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jEzDVyiMY37z",
      "metadata": {
        "id": "jEzDVyiMY37z"
      },
      "source": [
        "Once model training is done, you can generate predictions by running `.predict()` method on `pipeline` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z2sOiMID4X2-",
      "metadata": {
        "id": "Z2sOiMID4X2-"
      },
      "outputs": [],
      "source": [
        "pipeline.predict(\n",
        "    input_table_name='prediction_data',  # table that contains features to predict with.\n",
        "    model_resource_name='4028856894775885824',  #The resource name of the Vertex AI model - printed upon completion of the previous step or can be viewed via the Vertex AI dashboard(under 'Models' for the selected region).\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ak21YwEHY37z",
      "metadata": {
        "id": "ak21YwEHY37z"
      },
      "source": [
        "There are 2 additional optional  parameters:\n",
        "* `model_name` - name of the model specified at `train` step. (default is 'crystalvalue_model')\n",
        "* `destination_table` - name of BigQuery table that contains predictions. (default is 'predictions')`.    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "crystalvalue_demo_notebook.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/crystalvalue/crystalvalue_demo_notebook.ipynb?workspaceId=sumedhamenon:CrystalValue::citc",
          "timestamp": 1627656627042
        },
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/crystalvalue/crystalvalue_demo_notebook.ipynb?workspaceId=sumedhamenon:CrystalValue::citc",
          "timestamp": 1627656460877
        },
        {
          "file_id": "/piper/depot/google3/experimental/gtech_prem_data_science/projects/trac/treatwell/Crystal_Value_Demo_Notebook.ipynb?workspaceId=sumedhamenon:CrystalValue::citc",
          "timestamp": 1627648785641
        },
        {
          "file_id": "1JGQRDc1_luQsaMxx9ZZavddHBrgO7Xst",
          "timestamp": 1627648471137
        }
      ]
    },
    "environment": {
      "name": "common-cpu.mnightly-2021-01-05-debian-10-test",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-01-05-debian-10-test"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
